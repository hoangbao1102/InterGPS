{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mretinanet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m coco_eval\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mretinanet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csv_eval\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDA available: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from retinanet import model\n",
    "from retinanet.dataloader import CocoDataset, CSVDataset, collater, Resizer, AspectRatioBasedSampler, Augmenter, \\\n",
    "    Normalizer\n",
    "from retinanet import coco_eval\n",
    "from retinanet import csv_eval\n",
    "\n",
    "assert torch.__version__.split('.')[0] == '1'\n",
    "\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    parser = argparse.ArgumentParser(description='Simple training script for training a RetinaNet network.')\n",
    "\n",
    "    parser.add_argument('--dataset', help='Dataset type, must be one of csv or coco.')\n",
    "    parser.add_argument('--coco_path', help='Path to COCO directory')\n",
    "    parser.add_argument('--csv_train', help='Path to file containing training annotations (see readme)')\n",
    "    parser.add_argument('--csv_classes', help='Path to file containing class list (see readme)')\n",
    "    parser.add_argument('--csv_val', help='Path to file containing validation annotations (optional, see readme)')\n",
    "\n",
    "    parser.add_argument('--depth', help='Resnet depth, must be one of 18, 34, 50, 101, 152', type=int, default=152)\n",
    "    parser.add_argument('--batch_size', help='Number of training batch size', type=int, default=2)\n",
    "    parser.add_argument('--epochs', help='Number of epochs', type=int, default=100)\n",
    "    parser.add_argument('--lr', help='learning rate', type=float, default=1e-5)\n",
    "    parser.add_argument('--output_path', help='Path to saved models', type=str, default=\"models\")\n",
    "\n",
    "    parser = parser.parse_args(args)\n",
    "\n",
    "    os.makedirs(parser.output_path, exist_ok=True)\n",
    "\n",
    "    # Create the data loaders\n",
    "    if parser.dataset == 'coco':\n",
    "\n",
    "        if parser.coco_path is None:\n",
    "            raise ValueError('Must provide --coco_path when training on COCO,')\n",
    "\n",
    "        dataset_train = CocoDataset(parser.coco_path, set_name='train2017',\n",
    "                                    transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "        dataset_val = CocoDataset(parser.coco_path, set_name='val2017',\n",
    "                                  transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "\n",
    "    elif parser.dataset == 'csv':\n",
    "\n",
    "        if parser.csv_train is None:\n",
    "            raise ValueError('Must provide --csv_train when training on COCO,')\n",
    "\n",
    "        if parser.csv_classes is None:\n",
    "            raise ValueError('Must provide --csv_classes when training on COCO,')\n",
    "\n",
    "        dataset_train = CSVDataset(train_file=parser.csv_train, class_list=parser.csv_classes,\n",
    "                                   transform=transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\n",
    "\n",
    "        if parser.csv_val is None:\n",
    "            dataset_val = None\n",
    "            print('No validation annotations provided.')\n",
    "        else:\n",
    "            dataset_val = CSVDataset(train_file=parser.csv_val, class_list=parser.csv_classes,\n",
    "                                     transform=transforms.Compose([Normalizer(), Resizer()]))\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Dataset type not understood (must be csv or coco), exiting.')\n",
    "\n",
    "    sampler = AspectRatioBasedSampler(dataset_train, batch_size=parser.batch_size, drop_last=False)\n",
    "    dataloader_train = DataLoader(dataset_train, num_workers=4, collate_fn=collater, batch_sampler=sampler)\n",
    "\n",
    "    if dataset_val is not None:\n",
    "        sampler_val = AspectRatioBasedSampler(dataset_val, batch_size=1, drop_last=False)\n",
    "        dataloader_val = DataLoader(dataset_val, num_workers=4, collate_fn=collater, batch_sampler=sampler_val)\n",
    "\n",
    "    # Create the model\n",
    "    if parser.depth == 18:\n",
    "        retinanet = model.resnet18(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "    elif parser.depth == 34:\n",
    "        retinanet = model.resnet34(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "    elif parser.depth == 50:\n",
    "        retinanet = model.resnet50(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "    elif parser.depth == 101:\n",
    "        retinanet = model.resnet101(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "    elif parser.depth == 152:\n",
    "        retinanet = model.resnet152(num_classes=dataset_train.num_classes(), pretrained=True)\n",
    "    else:\n",
    "        raise ValueError('Unsupported model depth, must be one of 18, 34, 50, 101, 152')\n",
    "\n",
    "    use_gpu = True\n",
    "\n",
    "    if use_gpu:\n",
    "        if torch.cuda.is_available():\n",
    "            retinanet = retinanet.cuda()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        retinanet = torch.nn.DataParallel(retinanet).cuda()\n",
    "    else:\n",
    "        retinanet = torch.nn.DataParallel(retinanet)\n",
    "\n",
    "    retinanet.training = True\n",
    "\n",
    "    optimizer = optim.Adam(retinanet.parameters(), lr=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "    loss_hist = collections.deque(maxlen=500)\n",
    "\n",
    "    retinanet.train()\n",
    "    retinanet.module.freeze_bn()\n",
    "\n",
    "    print('Num training images: {}'.format(len(dataset_train)))\n",
    "\n",
    "    for epoch_num in range(parser.epochs):\n",
    "\n",
    "        retinanet.train()\n",
    "        retinanet.module.freeze_bn()\n",
    "\n",
    "        epoch_loss = []\n",
    "\n",
    "        for iter_num, data in enumerate(dataloader_train):\n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    classification_loss, regression_loss = retinanet([data['img'].cuda().float(), data['annot']])\n",
    "                else:\n",
    "                    classification_loss, regression_loss = retinanet([data['img'].float(), data['annot']])\n",
    "                    \n",
    "                classification_loss = classification_loss.mean()\n",
    "                regression_loss = regression_loss.mean()\n",
    "\n",
    "                loss = classification_loss + regression_loss\n",
    "\n",
    "                if bool(loss == 0):\n",
    "                    continue\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
    "                optimizer.step()\n",
    "\n",
    "                loss_hist.append(float(loss))\n",
    "                epoch_loss.append(float(loss))\n",
    "\n",
    "                print(\n",
    "                    'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
    "                        epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(loss_hist)))\n",
    "\n",
    "                del classification_loss\n",
    "                del regression_loss\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "        if parser.dataset == 'coco':\n",
    "            print('Evaluating dataset')\n",
    "            coco_eval.evaluate_coco(dataset_val, retinanet)\n",
    "\n",
    "        elif parser.dataset == 'csv' and parser.csv_val is not None:\n",
    "            print('Evaluating dataset')\n",
    "            mAP = csv_eval.evaluate(dataset_val, retinanet)\n",
    "            ave_acc = sum([value[0] * value[1] for key, value in mAP.items()]) / sum(\n",
    "                [value[1] for key, value in mAP.items()])\n",
    "            print(\"\\n[Average Acc]: %.6f\\n\" % ave_acc)\n",
    "\n",
    "        scheduler.step(np.mean(epoch_loss))\n",
    "\n",
    "        torch.save(retinanet.module, '{}/{}_retinanet_{}.pt'.format(parser.output_path, parser.dataset, epoch_num))\n",
    "        if os.path.exists('{}/{}_retinanet_{}.pt'.format(parser.output_path, parser.dataset, epoch_num-5)):\n",
    "            os.remove('{}/{}_retinanet_{}.pt'.format(parser.output_path, parser.dataset, epoch_num-5))\n",
    "            print(f\"{'{}/{}_retinanet_{}.pt'.format(parser.output_path, parser.dataset, epoch_num-5)} đã được xóa.\")\n",
    "        else:\n",
    "            print(f\"{'{}/{}_retinanet_{}.pt'.format(parser.output_path, parser.dataset, epoch_num-5)} không tồn tại.\")\n",
    "\n",
    "    retinanet.eval()\n",
    "\n",
    "    torch.save(retinanet, '{}/model_final.pt'.format(parser.output_path))\n",
    "\n",
    "    # Sau khi huấn luyện và lưu mô hình, gọi summary để xem kiến trúc\n",
    "    # Chú ý: Cần xác định kích thước đầu vào của mô hình. Ví dụ: (3, 800, 800) cho hình ảnh RGB kích thước 800x800.\n",
    "    summary(retinanet, input_size=(3, 800, 800))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvgps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
